{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN-ZT 10-fold cross validation\n",
    "### This notebook contains the code need to run a random 10 fold cross validation of a conditional generative adversarial network using [0,1] encoded individual toxicity matrices and chemicals structural data.\n",
    "#### See http://biorxiv.org/lookup/doi/10.1101/2020.10.02.322917 for details\n",
    "\n",
    "By Adrian J Green, PhD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Tensorflow and manage GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import multi_gpu_model\n",
    "\n",
    "tf.keras.backend.clear_session()  # For easy reset of notebook state.\n",
    "\n",
    "# minimize GPU useage by allowing memeory growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Python data handling and visualization modules, and local routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version 2.1.0 . Executing eagerly? True\n",
      "Number of GPUs:  1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# standard python\n",
    "import numpy as np\n",
    "# from sklearn.metrics import mean_squared_log_error, mean_squared_error\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "import pathlib\n",
    "import os.path\n",
    "import warnings\n",
    "import timeit\n",
    "\n",
    "# plotting, especially for jupyter notebooks\n",
    "# import matplotlib\n",
    "#matplotlib.rcParams['text.usetex'] = True # breaks for some endpoint labels\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from IPython.display import Image\n",
    "\n",
    "# pandas\n",
    "import pandas as pd\n",
    "\n",
    "# local routines\n",
    "from chemdataprep import load_PDBs\n",
    "from toxmathandler_AG import load_tmats, load_indv_tmats\n",
    "\n",
    "# NN build routines\n",
    "from NNbuild_train_vis import init_NN_v2\n",
    "\n",
    "# NN train routines\n",
    "from NNbuild_train_vis import discriminator_loss,generator_loss, get_train_function, write_training_file\n",
    "\n",
    "# Performance evaluation routines\n",
    "from gen_AggE import calc_AggE_indv, display_conf_matrix\n",
    "\n",
    "print(\"tensorflow version\",tf.__version__,\". Executing eagerly?\",tf.executing_eagerly())\n",
    "print(\"Number of GPUs: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Options and Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chemical structure and toxicity import and model output variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PDB options\n",
    "\n",
    "# cGAN & views parameters\n",
    "# [Gfeatures,Gbaselayers,Glayers,Dfeatures,Dbaselayers,Dlayers,carbonbased, setNatoms, views, ClassLabels]\n",
    "parameters = [279, 3, 11, 50, 0, 3, False, 82, 126, 1003] # GAN-ZT_v7\n",
    "\n",
    "## Option to base views on carbon or not. (Safe even if some have no carbon.)\n",
    "# Setting True will make the data smaller in memory and everything run faster.\n",
    "carbonbased = parameters[6]\n",
    "## Option for truncating the length of views.\n",
    "# Truncating will make the data and NN smaller and things run faster.\n",
    "# It make sense if we believe that looking at all neighborhoods of some size \n",
    "# gives sufficient understanding of the chemical.\n",
    "# setNatoms = None # use max number in data\n",
    "setNatoms = parameters[7] # truncate to this number\n",
    "useClassLabels = parameters[9] # allow cGAN to use class labels in training, None or int\n",
    "\n",
    "views=parameters[8]\n",
    "\n",
    "dataType = '(0,1)_18x1'\n",
    "\n",
    "if (dataType.find('(0,1)_18x6')!=-1):\n",
    "    concentrations = [0,1,2,3,4,5]\n",
    "else:\n",
    "    concentrations = [5]    ## Which of the available endpoints to use\n",
    "endpoints = [i for i in range(4,22)] # use all\n",
    "    \n",
    "genpath = 'AG-model-GT-'+dataType+'.h5'\n",
    "discpath = 'AG-model-DT-'+dataType+'.h5'\n",
    "\n",
    "# Traning individual toxic\n",
    "trpath = '/home2/ajgreen4/Read-Across_w_GAN/DataFiles/(0,1)_encoding_indv/Tox21_training_compounds/'\n",
    "valpath = '/home2/ajgreen4/Read-Across_w_GAN/DataFiles/(0,1)_encoding_indv/Tox21_validation_compounds/'\n",
    "allpath = '/home2/ajgreen4/Read-Across_w_GAN/DataFiles/(0,1)_encoding_indv/Tox21_all_train_compounds/'\n",
    "    \n",
    "modelpath = '/home2/ajgreen4/Read-Across_w_GAN/Models/'\n",
    "imageOut = '/home2/ajgreen4/Read-Across_w_GAN/imageOut/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cGAN variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss\n",
    "Gloss_function = tf.keras.losses.MeanSquaredError()\n",
    "Dloss_function = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "# optimizers\n",
    "generator_optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "### Load chemical data and vectorize into weights and views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1003 pdb files found at /home2/ajgreen4/Read-Across_w_GAN/DataFiles/(0,1)_encoding_indv/Tox21_all_train_compounds/PDBs/\n",
      "Species occurring = {'P', 'CL', 'B', 'N', 'O', 'F', 'BR', 'S', 'H', 'C', 'I', 'AS', 'SI'}\n",
      "Setting all views to Natoms= 82\n",
      "126 views needed, but setting to 126\n",
      "Maximum views used = 126\n",
      "Data tensor (w,v) shapes= (1003, 126) (1003, 126, 410)\n",
      "CPU times: user 1min 46s, sys: 245 ms, total: 1min 46s\n",
      "Wall time: 1min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# all training files\n",
    "[ws, vs, Natoms, Nviews, chemnames, Vshape] = load_PDBs(allpath,setNatoms=setNatoms,setNviews=views,carbonbased=carbonbased)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encode chemical labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chem_labels = np.arange(len(chemnames))\n",
    "chem_labels = np.reshape(chem_labels, (chem_labels.shape[0],1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load individual toxicity data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading individual toxicity matrices (~15 minutes)\n",
      "Number of chemicals= 1003\n",
      "Using concentrations ['64 uM']\n",
      "Using endpoints: ['MORT', 'YSE_', 'AXIS', 'EYE_', 'SNOU', 'JAW_', 'OTIC', 'PE__', 'BRAI', 'SOMI', 'PFIN', 'CFIN', 'PIG_', 'CIRC', 'TRUN', 'SWIM', 'NC__', 'TR__']\n",
      "Toxicity vector length Ntoxicity= 18\n",
      "Using 1 concentrations\n",
      "Using 18 endpoints\n",
      "CPU times: user 14min 47s, sys: 6.02 s, total: 14min 53s\n",
      "Wall time: 15min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# individual toxicity\n",
    "print(\"Loading individual toxicity matrices (~15 minutes)\")\n",
    "### Toxicity matrix options\n",
    "[toxicity,rows, cols, fish] = load_indv_tmats(allpath,chemnames,endpoint_indexes=endpoints,\n",
    "                                              SET=2, verbose=1)\n",
    "\n",
    "# legend labels for plotting\n",
    "print(\"Using\", len(concentrations), \"concentrations\")\n",
    "print(\"Using\", len(endpoints), \"endpoints\")\n",
    "endpoints = [i for i in range(len(rows))]\n",
    "concentrations = [i for i in range(len(cols))]\n",
    "legend = [rows,cols,endpoints,concentrations]\n",
    "    \n",
    "if 0:\n",
    "    print('CASRN: ',chemnames[0])\n",
    "    print('Chem label: ',fish[0])\n",
    "    print('First tox matrix:', toxicity[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network training code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create wrapper function to allow model to be discarded and re-initilazation between cross-validation folds\n",
    "def get_train_function():\n",
    "    # Compile training function\n",
    "    @tf.function\n",
    "    def train_step(G_data,real_data,chemClass,toxClass,doG=True,doD=True):\n",
    "        \"\"\"Train Condictional Generative Adversarial Network.\n",
    "\n",
    "        :parameter G_data: List containing a np.array vector with weights and \n",
    "                           a np.array matrix with vectorized views.\n",
    "                           (see chemdataprep.load_pdb())\n",
    "        :type G_data: list\n",
    "        :parameter real_data: Master toxicity data matrix. \n",
    "                              Rows correspond to chemicals and columns to toxicity measurements.\n",
    "                              (see toxmathandler.load_tmats())\n",
    "        :type real_data: np.array\n",
    "        :parameter chemClass: Chemical class label.\n",
    "        :type chemClass: int\n",
    "        :parameter toxClass: Toxcicity class labels.\n",
    "        :type toxClass: int\n",
    "        :parameter doG: If True train generator\n",
    "        :type doG: boolean\n",
    "        :parameter doD: If True train discriminator\n",
    "        :type doD: boolean\n",
    "\n",
    "        :returns: Discriminator and Generator loss\n",
    "        :rtype: tuple\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "            generated_matrix, Gpw_features = generator(G_data+chemClass, training=True)\n",
    "            expanded_Dpw_model = tf.repeat(Gpw_features, repeats=y, axis=0)\n",
    "\n",
    "            real_output = discriminator([expanded_Dpw_model]+real_data+toxClass, training=True)\n",
    "            fake_output = discriminator([Gpw_features]+[generated_matrix]+chemClass, training=True)\n",
    "\n",
    "            gen_loss = generator_loss(fake_output)\n",
    "            disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "            if doD:\n",
    "                # update discriminator\n",
    "                gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "                discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "                # Additional training\n",
    "                for i in range(2):\n",
    "                    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "                        generated_matrix, Gpw_features = generator(G_data+chemClass, training=False)\n",
    "                        expanded_Dpw_model = tf.repeat(Gpw_features, repeats=y, axis=0)\n",
    "\n",
    "                        real_output = discriminator([expanded_Dpw_model]+real_data+toxClass, training=True)\n",
    "                        fake_output = discriminator([Gpw_features]+[generated_matrix]+chemClass, \n",
    "                                                    training=True)\n",
    "\n",
    "\n",
    "                        gen_loss = generator_loss(fake_output)\n",
    "                        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "                    # update discriminator\n",
    "                    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "                    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "            if doG:\n",
    "                # update generator\n",
    "                gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "                generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "        return (gen_loss,disc_loss)\n",
    "    return train_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "gen_class_label (InputLayer)    [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "parallelwrapper_input0 (InputLa [(None, 126, 410)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gen_class_embedding (Embedding) (None, 1, 50)        50150       gen_class_label[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "gen_chem_feature_base (Model)   (None, 126, 279)     1428021     parallelwrapper_input0[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "parallelScalars (InputLayer)    [(None, 126)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gen_class_dense (Dense)         (None, 1, 279)       14229       gen_class_embedding[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "weighted_sum_over_views (Dot)   (None, 279)          0           gen_chem_feature_base[1][0]      \n",
      "                                                                 parallelScalars[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 279)          0           gen_class_dense[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "gen_label_merge (Concatenate)   (None, 558)          0           weighted_sum_over_views[0][0]    \n",
      "                                                                 reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Gft (Model)                     (None, 18)           3681234     gen_label_merge[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 5,173,634\n",
      "Trainable params: 5,160,206\n",
      "Non-trainable params: 13,428\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"discriminator\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "disc_class_label (InputLayer)   [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "disc_class_emmbedding (Embeddin (None, 1, 50)        50150       disc_class_label[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "disc_class_dense (Dense)        (None, 1, 50)        2550        disc_class_emmbedding[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Gpw_features (InputLayer)       [(None, 279)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 50)           0           disc_class_dense[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "toxicity_inputs (InputLayer)    [(None, 18)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "disc_label-tox_merge (Concatena (None, 347)          0           Gpw_features[0][0]               \n",
      "                                                                 reshape_1[0][0]                  \n",
      "                                                                 toxicity_inputs[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Dftj (Model)                    (None, 1)            368533      disc_label-tox_merge[0][0]       \n",
      "==================================================================================================\n",
      "Total params: 421,233\n",
      "Trainable params: 419,145\n",
      "Non-trainable params: 2,088\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initialize the cGAN\n",
    "doG = 1\n",
    "doD = 1\n",
    "if useClassLabels:\n",
    "    tf.keras.backend.clear_session()  # For easy reset of notebook state.\n",
    "    \n",
    "    # Initialize the G & D netowrks  \n",
    "    [generator, discriminator] = init_NN_v2([ws, vs],toxicity,parameters)\n",
    "    generator.summary()\n",
    "    discriminator.summary()\n",
    "\n",
    "# Shuffle split chemicals\n",
    "X = chem_labels\n",
    "# print(chem_labels.shape)\n",
    "ss = ShuffleSplit(n_splits=10, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Notes:\n",
    "- Generator wants gen_ability to be 1\n",
    "- Discriminator wants disc_ability to be 1 and gen_ability to be 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running fold :  1  of 10\n",
      "\n",
      "    Validation Dataset\n",
      "    Kappa:  0.134   AUROC:  0.589     SE 61.2\n",
      "    gen_ability: 0.037265867  disc_ability: 1.430598\n",
      "    Training State: doG = 1 , doD = 0  j =  0 \n",
      "\n",
      "0 \n",
      "    Validation Dataset\n",
      "    Kappa:  0.163   AUROC:  0.6055     SE 61.2\n",
      "    gen_ability: 0.045626413  disc_ability: 1.4746188\n",
      "    Training State: doG = 1 , doD = 0  j =  1 \n",
      "\n",
      "\n",
      "    Validation Dataset\n",
      "    Kappa:  0.167   AUROC:  0.5972     SE 51.0\n",
      "    gen_ability: 0.2560663  disc_ability: 0.48462793\n",
      "    Training State: doG = 1 , doD = 1  j =  18 \n",
      "\n",
      "25 \n",
      "    Validation Dataset\n",
      "    Kappa:  0.194   AUROC:  0.6219     SE 61.2\n",
      "    gen_ability: 0.4037956  disc_ability: 0.37176904\n",
      "    Training State: doG = 0 , doD = 1  j =  40 \n",
      "\n",
      "50 75 100 125 150 175 200 225 250 275 300 325 350 375 400 425 450 475 500 525 550 575 600 625 650 675 700 725 750 775 2216.4027229570784\n",
      "Running fold :  2  of 10\n",
      "0 \n",
      "    Validation Dataset\n",
      "    Kappa:  0.004   AUROC:  0.5061     SE 100.0\n",
      "    gen_ability: 0.0015555418  disc_ability: 1.0300919\n",
      "    Training State: doG = 1 , doD = 0  j =  5 \n",
      "\n",
      "\n",
      "    Validation Dataset\n",
      "    Kappa:  0.013   AUROC:  0.5182     SE 100.0\n",
      "    gen_ability: 0.003338846  disc_ability: 1.0538483\n",
      "    Training State: doG = 1 , doD = 0  j =  7 \n",
      "\n",
      "\n",
      "    Validation Dataset\n",
      "    Kappa:  0.018   AUROC:  0.5242     SE 100.0\n",
      "    gen_ability: 0.004067187  disc_ability: 1.0523281\n",
      "    Training State: doG = 1 , doD = 0  j =  8 \n",
      "\n",
      "\n",
      "    Validation Dataset\n",
      "    Kappa:  0.02   AUROC:  0.5273     SE 100.0\n",
      "    gen_ability: 0.0101090595  disc_ability: 1.076234\n",
      "    Training State: doG = 1 , doD = 0  j =  10 \n",
      "\n",
      "\n",
      "    Validation Dataset\n",
      "    Kappa:  0.023   AUROC:  0.5303     SE 100.0\n",
      "    gen_ability: 0.012253628  disc_ability: 1.0803491\n",
      "    Training State: doG = 1 , doD = 0  j =  11 \n",
      "\n",
      "\n",
      "    Validation Dataset\n",
      "    Kappa:  0.03   AUROC:  0.5394     SE 100.0\n",
      "    gen_ability: 0.01406029  disc_ability: 1.0899355\n",
      "    Training State: doG = 1 , doD = 0  j =  12 \n",
      "\n",
      "\n",
      "    Validation Dataset\n",
      "    Kappa:  0.031   AUROC:  0.5407     SE 97.2\n",
      "    gen_ability: 0.01979875  disc_ability: 1.094013\n",
      "    Training State: doG = 1 , doD = 0  j =  14 \n",
      "\n",
      "\n",
      "    Validation Dataset\n",
      "    Kappa:  0.05   AUROC:  0.5636     SE 100.0\n",
      "    gen_ability: 0.03852681  disc_ability: 1.0849565\n",
      "    Training State: doG = 1 , doD = 0  j =  15 \n",
      "\n",
      "25 \n",
      "    Validation Dataset\n",
      "    Kappa:  0.051   AUROC:  0.5596     SE 88.9\n",
      "    gen_ability: 0.1865003  disc_ability: 0.6733315\n",
      "    Training State: doG = 1 , doD = 1  j =  33 \n",
      "\n",
      "\n",
      "    Validation Dataset\n",
      "    Kappa:  0.147   AUROC:  0.6409     SE 83.3\n",
      "    gen_ability: 0.15445854  disc_ability: 0.67380553\n",
      "    Training State: doG = 1 , doD = 1  j =  34 \n",
      "\n",
      "50 75 100 125 \n",
      "    Validation Dataset\n",
      "    Kappa:  0.17   AUROC:  0.6381     SE 69.4\n",
      "    gen_ability: 0.0905887  disc_ability: 0.7089523\n",
      "    Training State: doG = 1 , doD = 1  j =  149 \n",
      "\n",
      "150 175 200 225 250 \n",
      "    Validation Dataset\n",
      "    Kappa:  0.176   AUROC:  0.646     SE 72.2\n",
      "    gen_ability: 0.084534615  disc_ability: 0.7399731\n",
      "    Training State: doG = 1 , doD = 1  j =  253 \n",
      "\n",
      "275 \n",
      "    Validation Dataset\n",
      "    Kappa:  0.18   AUROC:  0.649     SE 72.2\n",
      "    gen_ability: 0.08541872  disc_ability: 0.7429397\n",
      "    Training State: doG = 1 , doD = 1  j =  281 \n",
      "\n",
      "300 325 350 375 400 425 450 475 500 525 550 575 600 625 650 675 700 725 750 775 2162.6714714588597\n",
      "Running fold :  3  of 10\n",
      "\n",
      "    Validation Dataset\n",
      "    Kappa:  0.004   AUROC:  0.506     SE 100.0\n",
      "    gen_ability: 0.00018857284  disc_ability: 1.0037616\n",
      "    Training State: doG = 1 , doD = 0  j =  0 \n",
      "\n",
      "0 \n",
      "    Validation Dataset\n",
      "    Kappa:  0.013   AUROC:  0.5181     SE 100.0\n",
      "    gen_ability: 0.006051978  disc_ability: 1.0292442\n",
      "    Training State: doG = 1 , doD = 0  j =  11 \n",
      "\n",
      "25 \n",
      "    Validation Dataset\n",
      "    Kappa:  0.014   AUROC:  0.5167     SE 82.9\n",
      "    gen_ability: 0.2610975  disc_ability: 0.53882694\n",
      "    Training State: doG = 1 , doD = 1  j =  36 \n",
      "\n",
      "\n",
      "    Validation Dataset\n",
      "    Kappa:  0.033   AUROC:  0.54     SE 85.7\n",
      "    gen_ability: 0.19760159  disc_ability: 0.59244114\n",
      "    Training State: doG = 1 , doD = 1  j =  37 \n",
      "\n",
      "\n",
      "    Validation Dataset\n",
      "    Kappa:  0.043   AUROC:  0.5535     SE 91.4\n",
      "    gen_ability: 0.21546803  disc_ability: 0.6625756\n",
      "    Training State: doG = 1 , doD = 1  j =  40 \n",
      "\n",
      "50 75 100 125 150 175 200 225 250 275 300 325 350 375 400 425 450 475 500 525 550 575 600 625 650 \n",
      "    Validation Dataset\n",
      "    Kappa:  0.052   AUROC:  0.5648     SE 94.3\n",
      "    gen_ability: 0.09096148  disc_ability: 0.6850627\n",
      "    Training State: doG = 1 , doD = 1  j =  654 \n",
      "\n",
      "\n",
      "    Validation Dataset\n",
      "    Kappa:  0.063   AUROC:  0.5769     SE 94.3\n",
      "    gen_ability: 0.09193178  disc_ability: 0.68301976\n",
      "    Training State: doG = 1 , doD = 1  j =  655 \n",
      "\n",
      "675 700 725 750 775 2066.8292638440616\n",
      "Running fold :  4  of 10\n",
      "\n",
      "    Validation Dataset\n",
      "    Kappa:  0.011   AUROC:  0.5128     SE 97.6\n",
      "    gen_ability: 0.0447345  disc_ability: 1.2440492\n",
      "    Training State: doG = 1 , doD = 0  j =  0 \n",
      "\n",
      "0 \n",
      "    Validation Dataset\n",
      "    Kappa:  0.021   AUROC:  0.525     SE 100.0\n",
      "    gen_ability: 0.048110843  disc_ability: 1.3658098\n",
      "    Training State: doG = 1 , doD = 0  j =  1 \n",
      "\n",
      "\n",
      "    Validation Dataset\n",
      "    Kappa:  0.047   AUROC:  0.5462     SE 80.5\n",
      "    gen_ability: 0.57630956  disc_ability: 1.1629275\n",
      "    Training State: doG = 1 , doD = 0  j =  9 \n",
      "\n",
      "\n",
      "    Validation Dataset\n",
      "    Kappa:  0.068   AUROC:  0.5649     SE 80.5\n",
      "    gen_ability: 0.4827674  disc_ability: 1.0386134\n",
      "    Training State: doG = 1 , doD = 0  j =  10 \n",
      "\n",
      "25 50 75 100 125 150 175 \n",
      "    Validation Dataset\n",
      "    Kappa:  0.074   AUROC:  0.5555     SE 56.1\n",
      "    gen_ability: 0.076279856  disc_ability: 0.69452304\n",
      "    Training State: doG = 1 , doD = 1  j =  196 \n",
      "\n",
      "\n",
      "    Validation Dataset\n",
      "    Kappa:  0.101   AUROC:  0.5768     SE 61.0\n",
      "    gen_ability: 0.07480244  disc_ability: 0.6933377\n",
      "    Training State: doG = 1 , doD = 1  j =  197 \n",
      "\n",
      "200 225 250 275 300 325 350 375 400 425 450 475 500 525 550 575 600 625 650 675 700 725 750 775 2174.040382798994\n",
      "Running fold :  5  of 10\n",
      "0 \n",
      "    Validation Dataset\n",
      "    Kappa:  0.003   AUROC:  0.5031     SE 100.0\n",
      "    gen_ability: 0.0054156138  disc_ability: 1.0233403\n",
      "    Training State: doG = 1 , doD = 0  j =  8 \n",
      "\n",
      "\n",
      "    Validation Dataset\n",
      "    Kappa:  0.008   AUROC:  0.5094     SE 100.0\n",
      "    gen_ability: 0.0067273695  disc_ability: 1.0092311\n",
      "    Training State: doG = 1 , doD = 0  j =  9 \n",
      "\n",
      "\n",
      "    Validation Dataset\n",
      "    Kappa:  0.034   AUROC:  0.5384     SE 97.6\n",
      "    gen_ability: 0.017473564  disc_ability: 1.4285734\n",
      "    Training State: doG = 1 , doD = 0  j =  20 \n",
      "\n",
      "\n",
      "    Validation Dataset\n",
      "    Kappa:  0.042   AUROC:  0.5472     SE 100.0\n",
      "    gen_ability: 0.018928777  disc_ability: 1.3019272\n",
      "    Training State: doG = 1 , doD = 0  j =  25 \n",
      "\n",
      "25 \n",
      "    Validation Dataset\n",
      "    Kappa:  0.046   AUROC:  0.551     SE 97.6\n",
      "    gen_ability: 0.028835654  disc_ability: 1.1368679\n",
      "    Training State: doG = 1 , doD = 0  j =  26 \n",
      "\n",
      "\n",
      "    Validation Dataset\n",
      "    Kappa:  0.058   AUROC:  0.5636     SE 97.6\n",
      "    gen_ability: 0.051812887  disc_ability: 0.98345584\n",
      "    Training State: doG = 1 , doD = 0  j =  27 \n",
      "\n",
      "\n",
      "    Validation Dataset\n",
      "    Kappa:  0.07   AUROC:  0.5694     SE 88.1\n",
      "    gen_ability: 0.0818283  disc_ability: 0.85412186\n",
      "    Training State: doG = 1 , doD = 1  j =  28 \n",
      "\n",
      "\n",
      "    Validation Dataset\n",
      "    Kappa:  0.076   AUROC:  0.5775     SE 92.9\n",
      "    gen_ability: 0.20910057  disc_ability: 0.7833004\n",
      "    Training State: doG = 1 , doD = 1  j =  37 \n",
      "\n",
      "\n",
      "    Validation Dataset\n",
      "    Kappa:  0.115   AUROC:  0.6146     SE 95.2\n",
      "    gen_ability: 0.6190994  disc_ability: 0.69525975\n",
      "    Training State: doG = 0 , doD = 1  j =  39 \n",
      "\n",
      "\n",
      "    Validation Dataset\n",
      "    Kappa:  0.154   AUROC:  0.646     SE 95.2\n",
      "    gen_ability: 0.1552005  disc_ability: 0.8245148\n",
      "    Training State: doG = 1 , doD = 1  j =  40 \n",
      "\n",
      "\n",
      "    Validation Dataset\n",
      "    Kappa:  0.181   AUROC:  0.6575     SE 88.1\n",
      "    gen_ability: 0.113065004  disc_ability: 0.71145874\n",
      "    Training State: doG = 1 , doD = 1  j =  41 \n",
      "\n",
      "50 75 \n",
      "    Validation Dataset\n",
      "    Kappa:  0.206   AUROC:  0.6813     SE 92.9\n",
      "    gen_ability: 0.10669846  disc_ability: 0.6888888\n",
      "    Training State: doG = 1 , doD = 1  j =  89 \n",
      "\n",
      "100 125 150 175 200 225 250 275 300 325 350 \n",
      "    Validation Dataset\n",
      "    Kappa:  0.208   AUROC:  0.595     SE 31.0\n",
      "    gen_ability: 0.10652982  disc_ability: 0.6147313\n",
      "    Training State: doG = 1 , doD = 1  j =  370 \n",
      "\n",
      "\n",
      "    Validation Dataset\n",
      "    Kappa:  0.214   AUROC:  0.6006     SE 33.3\n",
      "    gen_ability: 0.113827206  disc_ability: 0.61044085\n",
      "    Training State: doG = 1 , doD = 1  j =  371 \n",
      "\n",
      "375 400 425 450 475 500 525 550 575 600 625 650 675 700 725 \n",
      "    Validation Dataset\n",
      "    Kappa:  0.218   AUROC:  0.6404     SE 59.5\n",
      "    gen_ability: 0.12980734  disc_ability: 0.57609636\n",
      "    Training State: doG = 1 , doD = 1  j =  740 \n",
      "\n",
      "750 775 2229.830689470982\n",
      "Running fold :  6  of 10\n",
      "0 \n",
      "    Validation Dataset\n",
      "    Kappa:  0.002   AUROC:  0.503     SE 100.0\n",
      "    gen_ability: 0.00046065458  disc_ability: 1.0184242\n",
      "    Training State: doG = 1 , doD = 0  j =  1 \n",
      "\n",
      "\n",
      "    Validation Dataset\n",
      "    Kappa:  0.004   AUROC:  0.5059     SE 100.0\n",
      "    gen_ability: 0.0060121235  disc_ability: 1.1702169\n",
      "    Training State: doG = 1 , doD = 0  j =  4 \n",
      "\n",
      "\n",
      "    Validation Dataset\n",
      "    Kappa:  0.01   AUROC:  0.5148     SE 100.0\n",
      "    gen_ability: 0.009460316  disc_ability: 1.2502307\n",
      "    Training State: doG = 1 , doD = 0  j =  5 \n",
      "\n",
      "\n",
      "    Validation Dataset\n",
      "    Kappa:  0.014   AUROC:  0.5207     SE 100.0\n",
      "    gen_ability: 1.4890888  disc_ability: 1.1524993\n",
      "    Training State: doG = 1 , doD = 1  j =  15 \n",
      "\n",
      "25 \n",
      "    Validation Dataset\n",
      "    Kappa:  0.055   AUROC:  0.5715     SE 90.6\n",
      "    gen_ability: 0.16103625  disc_ability: 0.6022489\n",
      "    Training State: doG = 1 , doD = 1  j =  32 \n",
      "\n",
      "\n",
      "    Validation Dataset\n",
      "    Kappa:  0.065   AUROC:  0.5787     SE 84.4\n",
      "    gen_ability: 0.13365276  disc_ability: 0.6613438\n",
      "    Training State: doG = 1 , doD = 1  j =  34 \n",
      "\n",
      "\n",
      "    Validation Dataset\n",
      "    Kappa:  0.073   AUROC:  0.5838     SE 81.2\n",
      "    gen_ability: 0.16131063  disc_ability: 0.630011\n",
      "    Training State: doG = 1 , doD = 1  j =  35 \n",
      "\n",
      "\n",
      "    Validation Dataset\n",
      "    Kappa:  0.094   AUROC:  0.6045     SE 81.2\n",
      "    gen_ability: 0.12737103  disc_ability: 0.6838014\n",
      "    Training State: doG = 1 , doD = 1  j =  36 \n",
      "\n",
      "50 75 100 \n",
      "    Validation Dataset\n",
      "    Kappa:  0.101   AUROC:  0.5944     SE 65.6\n",
      "    gen_ability: 0.09782548  disc_ability: 0.62243366\n",
      "    Training State: doG = 1 , doD = 1  j =  106 \n",
      "\n",
      "125 150 175 200 225 \n",
      "    Validation Dataset\n",
      "    Kappa:  0.105   AUROC:  0.5426     SE 15.6\n",
      "    gen_ability: 0.2178344  disc_ability: 0.60441107\n",
      "    Training State: doG = 1 , doD = 1  j =  229 \n",
      "\n",
      "250 275 300 325 350 \n",
      "    Validation Dataset\n",
      "    Kappa:  0.122   AUROC:  0.5751     SE 37.5\n",
      "    gen_ability: 0.2345857  disc_ability: 0.62459666\n",
      "    Training State: doG = 1 , doD = 1  j =  361 \n",
      "\n",
      "375 400 425 450 \n",
      "    Validation Dataset\n",
      "    Kappa:  0.166   AUROC:  0.5996     SE 40.6\n",
      "    gen_ability: 0.13386208  disc_ability: 0.5858501\n",
      "    Training State: doG = 1 , doD = 1  j =  458 \n",
      "\n",
      "475 500 525 550 575 600 625 650 675 700 725 750 775 2220.7784132838715\n",
      "Running fold :  7  of 10\n",
      "\n",
      "    Validation Dataset\n",
      "    Kappa:  0.065   AUROC:  0.5734     SE 82.4\n",
      "    gen_ability: 0.0042780754  disc_ability: 1.058222\n",
      "    Training State: doG = 1 , doD = 0  j =  0 \n",
      "\n",
      "0 25 50 \n",
      "    Validation Dataset\n",
      "    Kappa:  0.1   AUROC:  0.557     SE 32.4\n",
      "    gen_ability: 0.051583435  disc_ability: 0.82682383\n",
      "    Training State: doG = 1 , doD = 1  j =  67 \n",
      "\n",
      "75 100 125 150 175 200 \n",
      "    Validation Dataset\n",
      "    Kappa:  0.107   AUROC:  0.5572     SE 29.4\n",
      "    gen_ability: 0.10231911  disc_ability: 0.6676694\n",
      "    Training State: doG = 1 , doD = 1  j =  215 \n",
      "\n",
      "225 250 \n",
      "    Validation Dataset\n",
      "    Kappa:  0.135   AUROC:  0.5804     SE 38.2\n",
      "    gen_ability: 0.09473786  disc_ability: 0.7156119\n",
      "    Training State: doG = 1 , doD = 1  j =  251 \n",
      "\n",
      "\n",
      "    Validation Dataset\n",
      "    Kappa:  0.15   AUROC:  0.5752     SE 29.4\n",
      "    gen_ability: 0.094302654  disc_ability: 0.71297973\n",
      "    Training State: doG = 1 , doD = 1  j =  253 \n",
      "\n",
      "275 \n",
      "    Validation Dataset\n",
      "    Kappa:  0.158   AUROC:  0.5867     SE 35.3\n",
      "    gen_ability: 0.105775416  disc_ability: 0.6923453\n",
      "    Training State: doG = 1 , doD = 1  j =  284 \n",
      "\n",
      "\n",
      "    Validation Dataset\n",
      "    Kappa:  0.165   AUROC:  0.615     SE 52.9\n",
      "    gen_ability: 0.10878378  disc_ability: 0.70447886\n",
      "    Training State: doG = 1 , doD = 1  j =  291 \n",
      "\n",
      "\n",
      "    Validation Dataset\n",
      "    Kappa:  0.166   AUROC:  0.5812     SE 29.4\n",
      "    gen_ability: 0.109974496  disc_ability: 0.6973645\n",
      "    Training State: doG = 1 , doD = 1  j =  292 \n",
      "\n",
      "300 325 350 375 400 425 450 475 500 525 550 575 600 625 650 675 700 725 750 775 2062.3217784899753\n",
      "Running fold :  8  of 10\n",
      "0 \n",
      "    Validation Dataset\n",
      "    Kappa:  0.002   AUROC:  0.5029     SE 100.0\n",
      "    gen_ability: 0.0005920111  disc_ability: 1.0065483\n",
      "    Training State: doG = 1 , doD = 0  j =  6 \n",
      "\n",
      "\n",
      "    Validation Dataset\n",
      "    Kappa:  0.003   AUROC:  0.5058     SE 100.0\n",
      "    gen_ability: 0.0068588946  disc_ability: 1.0067011\n",
      "    Training State: doG = 1 , doD = 0  j =  8 \n",
      "\n",
      "\n",
      "    Validation Dataset\n",
      "    Kappa:  0.007   AUROC:  0.5116     SE 100.0\n",
      "    gen_ability: 0.027330363  disc_ability: 1.0131971\n",
      "    Training State: doG = 1 , doD = 0  j =  9 \n",
      "\n",
      "\n",
      "    Validation Dataset\n",
      "    Kappa:  0.008   AUROC:  0.5145     SE 100.0\n",
      "    gen_ability: 0.09818593  disc_ability: 1.0192236\n",
      "    Training State: doG = 1 , doD = 0  j =  12 \n",
      "\n",
      "\n",
      "    Validation Dataset\n",
      "    Kappa:  0.013   AUROC:  0.5231     SE 100.0\n",
      "    gen_ability: 0.13166125  disc_ability: 1.005426\n",
      "    Training State: doG = 1 , doD = 0  j =  13 \n",
      "\n",
      "\n",
      "    Validation Dataset\n",
      "    Kappa:  0.021   AUROC:  0.5342     SE 96.4\n",
      "    gen_ability: 0.16335595  disc_ability: 1.0060655\n",
      "    Training State: doG = 1 , doD = 0  j =  14 \n",
      "\n",
      "\n",
      "    Validation Dataset\n",
      "    Kappa:  0.031   AUROC:  0.552     SE 100.0\n",
      "    gen_ability: 0.20247416  disc_ability: 1.0135988\n",
      "    Training State: doG = 1 , doD = 0  j =  15 \n",
      "\n",
      "25 \n",
      "    Validation Dataset\n",
      "    Kappa:  0.045   AUROC:  0.561     SE 82.1\n",
      "    gen_ability: 0.16629742  disc_ability: 0.58300525\n",
      "    Training State: doG = 1 , doD = 1  j =  39 \n",
      "\n",
      "\n",
      "    Validation Dataset\n",
      "    Kappa:  0.052   AUROC:  0.5697     SE 82.1\n",
      "    gen_ability: 0.17442003  disc_ability: 0.5603187\n",
      "    Training State: doG = 1 , doD = 1  j =  40 \n",
      "\n",
      "\n",
      "    Validation Dataset\n",
      "    Kappa:  0.057   AUROC:  0.5896     SE 100.0\n",
      "    gen_ability: 0.24696206  disc_ability: 0.511154\n",
      "    Training State: doG = 1 , doD = 1  j =  42 \n",
      "\n",
      "50 75 100 125 \n",
      "    Validation Dataset\n",
      "    Kappa:  0.098   AUROC:  0.6188     SE 82.1\n",
      "    gen_ability: 0.120221525  disc_ability: 0.6168259\n",
      "    Training State: doG = 1 , doD = 1  j =  137 \n",
      "\n",
      "150 175 \n",
      "    Validation Dataset\n",
      "    Kappa:  0.118   AUROC:  0.6133     SE 64.3\n",
      "    gen_ability: 0.11665566  disc_ability: 0.61603236\n",
      "    Training State: doG = 1 , doD = 1  j =  181 \n",
      "\n",
      "\n",
      "    Validation Dataset\n",
      "    Kappa:  0.136   AUROC:  0.6375     SE 71.4\n",
      "    gen_ability: 0.108038776  disc_ability: 0.62645805\n",
      "    Training State: doG = 1 , doD = 1  j =  183 \n",
      "\n",
      "200 225 250 275 300 325 350 375 400 425 450 475 500 525 550 575 600 625 650 675 700 725 750 775 2194.2269142400473\n",
      "Running fold :  9  of 10\n",
      "\n",
      "    Validation Dataset\n",
      "    Kappa:  0.004   AUROC:  0.506     SE 100.0\n",
      "    gen_ability: 1.3986182e-05  disc_ability: 1.0017297\n",
      "    Training State: doG = 1 , doD = 0  j =  0 \n",
      "\n",
      "0 \n",
      "    Validation Dataset\n",
      "    Kappa:  0.008   AUROC:  0.5119     SE 100.0\n",
      "    gen_ability: 0.0071607055  disc_ability: 1.0057122\n",
      "    Training State: doG = 1 , doD = 0  j =  3 \n",
      "\n",
      "\n",
      "    Validation Dataset\n",
      "    Kappa:  0.016   AUROC:  0.5238     SE 100.0\n",
      "    gen_ability: 0.05416575  disc_ability: 1.0233357\n",
      "    Training State: doG = 1 , doD = 0  j =  4 \n",
      "\n",
      "\n",
      "    Validation Dataset\n",
      "    Kappa:  0.047   AUROC:  0.5655     SE 100.0\n",
      "    gen_ability: 0.036226902  disc_ability: 1.1133068\n",
      "    Training State: doG = 1 , doD = 0  j =  9 \n",
      "\n",
      "\n",
      "    Validation Dataset\n",
      "    Kappa:  0.072   AUROC:  0.5952     SE 100.0\n",
      "    gen_ability: 0.019673137  disc_ability: 1.1380017\n",
      "    Training State: doG = 1 , doD = 0  j =  10 \n",
      "\n",
      "25 50 75 100 \n",
      "    Validation Dataset\n",
      "    Kappa:  0.074   AUROC:  0.5547     SE 45.5\n",
      "    gen_ability: 0.07139424  disc_ability: 0.69570625\n",
      "    Training State: doG = 1 , doD = 1  j =  121 \n",
      "\n",
      "125 \n",
      "    Validation Dataset\n",
      "    Kappa:  0.097   AUROC:  0.5663     SE 42.4\n",
      "    gen_ability: 0.08023766  disc_ability: 0.67121536\n",
      "    Training State: doG = 1 , doD = 1  j =  131 \n",
      "\n",
      "150 \n",
      "    Validation Dataset\n",
      "    Kappa:  0.133   AUROC:  0.5777     SE 36.4\n",
      "    gen_ability: 0.08642945  disc_ability: 0.6744371\n",
      "    Training State: doG = 1 , doD = 1  j =  170 \n",
      "\n",
      "175 200 \n",
      "    Validation Dataset\n",
      "    Kappa:  0.148   AUROC:  0.5931     SE 42.4\n",
      "    gen_ability: 0.09518072  disc_ability: 0.6228755\n",
      "    Training State: doG = 1 , doD = 1  j =  210 \n",
      "\n",
      "225 250 275 \n",
      "    Validation Dataset\n",
      "    Kappa:  0.179   AUROC:  0.6364     SE 60.6\n",
      "    gen_ability: 0.085269555  disc_ability: 0.67323065\n",
      "    Training State: doG = 1 , doD = 1  j =  286 \n",
      "\n",
      "300 325 350 375 400 425 450 475 500 525 \n",
      "    Validation Dataset\n",
      "    Kappa:  0.215   AUROC:  0.6667     SE 66.7\n",
      "    gen_ability: 0.08725835  disc_ability: 0.62824434\n",
      "    Training State: doG = 1 , doD = 1  j =  550 \n",
      "\n",
      "550 575 600 625 650 675 700 725 750 775 2234.5057556610554\n",
      "Running fold :  10  of 10\n",
      "0 \n",
      "    Validation Dataset\n",
      "    Kappa:  0.002   AUROC:  0.5031     SE 100.0\n",
      "    gen_ability: 0.0061282725  disc_ability: 1.0243341\n",
      "    Training State: doG = 1 , doD = 0  j =  3 \n",
      "\n",
      "\n",
      "    Validation Dataset\n",
      "    Kappa:  0.008   AUROC:  0.5093     SE 100.0\n",
      "    gen_ability: 0.13335657  disc_ability: 1.2097838\n",
      "    Training State: doG = 1 , doD = 0  j =  10 \n",
      "\n",
      "\n",
      "    Validation Dataset\n",
      "    Kappa:  0.01   AUROC:  0.5124     SE 100.0\n",
      "    gen_ability: 0.6616933  disc_ability: 1.1819348\n",
      "    Training State: doG = 1 , doD = 0  j =  24 \n",
      "\n",
      "\n",
      "    Validation Dataset\n",
      "    Kappa:  0.013   AUROC:  0.5155     SE 100.0\n",
      "    gen_ability: 0.5960993  disc_ability: 1.1180018\n",
      "    Training State: doG = 1 , doD = 0  j =  25 \n",
      "\n",
      "25 \n",
      "    Validation Dataset\n",
      "    Kappa:  0.029   AUROC:  0.534     SE 95.0\n",
      "    gen_ability: 0.18294714  disc_ability: 0.645192\n",
      "    Training State: doG = 1 , doD = 1  j =  36 \n",
      "\n",
      "\n",
      "    Validation Dataset\n",
      "    Kappa:  0.039   AUROC:  0.5432     SE 90.0\n",
      "    gen_ability: 0.22293444  disc_ability: 0.6251925\n",
      "    Training State: doG = 1 , doD = 1  j =  38 \n",
      "\n",
      "\n",
      "    Validation Dataset\n",
      "    Kappa:  0.059   AUROC:  0.5617     SE 87.5\n",
      "    gen_ability: 0.21054673  disc_ability: 0.6233338\n",
      "    Training State: doG = 1 , doD = 1  j =  39 \n",
      "\n",
      "\n",
      "    Validation Dataset\n",
      "    Kappa:  0.111   AUROC:  0.6083     SE 87.5\n",
      "    gen_ability: 0.18479128  disc_ability: 0.65337765\n",
      "    Training State: doG = 1 , doD = 1  j =  40 \n",
      "\n",
      "50 75 100 125 150 175 200 225 \n",
      "    Validation Dataset\n",
      "    Kappa:  0.151   AUROC:  0.5819     SE 37.5\n",
      "    gen_ability: 0.1457302  disc_ability: 0.5031005\n",
      "    Training State: doG = 1 , doD = 1  j =  229 \n",
      "\n",
      "\n",
      "    Validation Dataset\n",
      "    Kappa:  0.164   AUROC:  0.569     SE 22.5\n",
      "    gen_ability: 0.12111667  disc_ability: 0.531967\n",
      "    Training State: doG = 1 , doD = 1  j =  231 \n",
      "\n",
      "250 275 300 325 350 375 400 425 450 475 500 \n",
      "    Validation Dataset\n",
      "    Kappa:  0.165   AUROC:  0.5754     SE 27.5\n",
      "    gen_ability: 0.11208974  disc_ability: 0.5367658\n",
      "    Training State: doG = 1 , doD = 1  j =  516 \n",
      "\n",
      "525 550 575 600 625 650 675 700 725 750 775 2250.092442050809\n",
      "CPU times: user 7h 9min 2s, sys: 51min 51s, total: 8h 54s\n",
      "Wall time: 6h 3min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "verbose = 0\n",
    "# cGAN training loop with 10-fold cross-validation\n",
    "k = 1\n",
    "# Set which of G or D or both trains.\n",
    "for train_index, test_index in ss.split(X): \n",
    "    start_time = timeit.default_timer()\n",
    "    print(\"Running fold : \", k, \" of 10\")\n",
    "    fish_index = []\n",
    "    for chemical in train_index:\n",
    "        results = np.where(fish == chemical)\n",
    "        fish_index.extend(results[0].tolist())\n",
    "    fish_index = np.array(fish_index)\n",
    "    fish_index = fish_index.flatten()\n",
    "    chem_index = train_index.flatten()\n",
    "\n",
    "    ws_foldT = ws[chem_index]\n",
    "    vs_foldT = vs[chem_index]\n",
    "    chem_labels_foldT = chem_labels[:len(chem_index)] # rename chemical labels 0 - 801\n",
    "\n",
    "    toxicity_foldT = toxicity[fish_index]\n",
    "    fish_foldT = fish[fish_index]\n",
    "\n",
    "    # raname toxicity labels 0 - 801\n",
    "    chem_index_sorted = np.sort(chem_index)\n",
    "    l = 0\n",
    "    for label in chem_index_sorted:\n",
    "        fish_foldT[fish_foldT == label] = l\n",
    "        l += 1\n",
    "\n",
    "    y = np.bincount(fish_foldT[:,0])\n",
    "    y = y[y != 0]\n",
    "\n",
    "    fish_index = []\n",
    "    for chemical in test_index:\n",
    "        results = np.where(fish == chemical)\n",
    "        fish_index.extend(results[0].tolist())\n",
    "    fish_index = np.array(fish_index)\n",
    "    fish_index = fish_index.flatten()\n",
    "    chem_index = test_index.flatten()\n",
    "\n",
    "    ws_V = ws[chem_index]\n",
    "    vs_V = vs[chem_index]\n",
    "\n",
    "    # Create validation chemical list\n",
    "    chemnames_array = np.array(chemnames)\n",
    "    chemnames_V = chemnames_array[chem_index]\n",
    "    chemnames_V = chemnames_V.tolist()\n",
    "\n",
    "    chem_labels_V = chem_labels[:len(chem_index)]\n",
    "\n",
    "    toxicity_V = toxicity[fish_index]\n",
    "    fish_V = fish[fish_index]\n",
    "\n",
    "    # raname toxicity labels 0 - 801\n",
    "    chem_index_sorted = np.sort(chem_index)\n",
    "    l = 0\n",
    "    for label in chem_index_sorted:\n",
    "        fish_V[fish_V == label] = l\n",
    "        l += 1\n",
    "\n",
    "    toxicity_V = toxicity[fish_index]\n",
    "    fish_V = fish[:len(fish_index)]\n",
    "    z = np.bincount(fish_V[:,0])\n",
    "    z = z[z != 0]        \n",
    "\n",
    "    epochs = 800\n",
    "    best_kappa = 0\n",
    "    training_loss = np.zeros((epochs,2))\n",
    "    val_loss = np.zeros((epochs,2))\n",
    "    train_step = get_train_function()\n",
    "    j = 0\n",
    "    while j < epochs:\n",
    "        info = train_step([ws_foldT,vs_foldT],[toxicity_foldT],[chem_labels_foldT],[fish_foldT],doG,doD)\n",
    "\n",
    "        # find out how well the two NNs are doing on training set\n",
    "        gen_lab, Gchem_features = generator.predict([ws_foldT,vs_foldT,chem_labels_foldT])\n",
    "        expanded_Dpw_model = tf.repeat(Gchem_features, repeats=y, axis=0)\n",
    "\n",
    "        fake_output = discriminator.predict([Gchem_features,gen_lab,chem_labels_foldT])\n",
    "        gen_ability_T = Dloss_function(tf.zeros_like(fake_output), fake_output).numpy()\n",
    "\n",
    "        real_output = discriminator.predict([expanded_Dpw_model,toxicity_foldT,fish_foldT])\n",
    "        disc_ability_T = Dloss_function(tf.ones_like(real_output), real_output).numpy()\n",
    "\n",
    "        doG = 1\n",
    "        doD = 1\n",
    "\n",
    "        # if G is winning stop training G\n",
    "        if (disc_ability_T-gen_ability_T) < 0 or gen_ability_T > 0.95:\n",
    "            doG = 0\n",
    "        # if D is winning stop training D\n",
    "        if disc_ability_T > 0.95:\n",
    "            doD = 0\n",
    "        if gen_ability_T > 0.90 and disc_ability_T > 0.90:\n",
    "            doG = 1\n",
    "            doD = 1            \n",
    "\n",
    "        # find out how well the two NNs are doing on validation set\n",
    "        gen_lab_V, Gchem_features_V = generator.predict([ws_V,vs_V,chem_labels_V])\n",
    "        expanded_Dpw_model_V = tf.repeat(Gchem_features_V, repeats=z, axis=0)\n",
    "\n",
    "        fake_output_V = discriminator.predict([Gchem_features_V,gen_lab_V,chem_labels_V])\n",
    "        gen_ability_V = Dloss_function(tf.zeros_like(fake_output_V), fake_output_V).numpy()\n",
    "\n",
    "        real_output_V = discriminator.predict([expanded_Dpw_model_V,toxicity_V,fish_V])\n",
    "        disc_ability_V = Dloss_function(tf.ones_like(real_output_V), real_output_V).numpy()\n",
    "\n",
    "        # Calculate chemical activity - ignoring warning due to potential division by zero\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(action='ignore', category=Warning)\n",
    "            [gen_activity_table, tox_activity_table, gen_AggE, tox_AggE] = calc_AggE_indv(toxicity_V, chem_labels_V, \n",
    "                                                                                          chemnames_V, gen_lab_V, \n",
    "                                                                                          fish_V, endpoints, z)\n",
    "\n",
    "            metrics = display_conf_matrix(gen_activity_table, tox_activity_table)\n",
    "        model_kappa = metrics[0]\n",
    "\n",
    "        if verbose:\n",
    "            print(\"\\nTraining Dataset\")\n",
    "            print('    Kappa: ', metrics[0], '  AUROC: ', metrics[1], '    SE', metrics[2])\n",
    "            print(\"gen_ability:\", gen_ability_T, \" disc_ability:\", disc_ability_T)\n",
    "            print(\"Training State: doG =\", doG, \", doD =\", doD, \" j = \", j, \"\\n\")\n",
    "\n",
    "        if model_kappa > best_kappa:\n",
    "            best_kappa = model_kappa\n",
    "            best_metrics = metrics\n",
    "\n",
    "            # find out how well the two NNs are doing\n",
    "            print(\"\\n    Validation Dataset\")\n",
    "            print('    Kappa: ', metrics[0], '  AUROC: ', metrics[1], '    SE', metrics[2])\n",
    "            print(\"    gen_ability:\", gen_ability_V, \" disc_ability:\", disc_ability_V)\n",
    "            print(\"    Training State: doG =\", doG, \", doD =\", doD, \" j = \", j, \"\\n\")\n",
    "\n",
    "        if j % 25 == 0:\n",
    "            print(j, end=\" \")\n",
    "        training_loss[j] = [gen_ability_T, disc_ability_T]\n",
    "        val_loss[j] = [gen_ability_V, disc_ability_V]\n",
    "        j += 1\n",
    "    k += 1\n",
    "\n",
    "    # Save training results\n",
    "    best_kappa_f = round(best_kappa,5)\n",
    "\n",
    "    model_ID = \"AG-model-GT-\"+dataType+\"-Kappa-\"+str(best_kappa_f)+\"-\"+str(k)+\"-fold.h5\"\n",
    "\n",
    "    summary_file_df = write_training_file(parameters,[model_ID, concentrations, ws.shape[1], gen_ability_V, disc_ability_V],\n",
    "                                  best_metrics, '/home2/ajgreen4/Read-Across_w_GAN/output/10-fold-crossval-4-14-21.xlsx')\n",
    "\n",
    "    # Re-initialize the cGAN\n",
    "    doG = 1\n",
    "    doD = 1\n",
    "    # Initialize the G & D netowrks  \n",
    "    [generator, discriminator] = init_NN_v2([ws, vs],toxicity,parameters)\n",
    "\n",
    "    # Determine time taken to run fold\n",
    "    elapsed = timeit.default_timer() - start_time\n",
    "    print(elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os._exit(00)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
